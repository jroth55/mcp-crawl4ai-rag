# The transport for the MCP server - either 'sse' or 'stdio' (defaults to sse if left empty)
TRANSPORT=

# Host to bind to if using sse as the transport (leave empty if using stdio)
HOST=

# Port to listen on if using sse as the transport (leave empty if using stdio)
PORT=

# API key for authenticating requests to the MCP server when using SSE transport
# This provides basic authentication for the server endpoints
# Leave empty to disable authentication (not recommended for production)
MCP_SERVER_API_KEY=

# Get your Open AI API Key by following these instructions -
# https://help.openai.com/en/articles/4936850-where-do-i-find-my-openai-api-key
# Default embedding model: text-embedding-3-small (1536 dimensions)
# Note: text-embedding-3-large is not supported due to database limitations
OPENAI_API_KEY=

# The LLM you want to use for contextual embeddings (contextual retrieval)
# Leave this blank if you do not want to use contextual embeddings
# Recommended: deepseek/deepseek-r1-distill-qwen-32b (best value at ~$0.15/M tokens via OpenRouter)
# Alternative: gpt-4.1-mini (OpenAI ecosystem, 1M context at ~$0.38/M tokens)
# Fast option: google/gemini-2.5-flash (ultra-fast 380 TPS at ~$0.21/M tokens via OpenRouter)
MODEL_CHOICE=deepseek/deepseek-r1-distill-qwen-32b

# OpenRouter API Key (required if using OpenRouter models like DeepSeek or Google models)
# Get your API key from https://openrouter.ai/keys
OPENROUTER_API_KEY=

# For the Supabase version (sample_supabase_agent.py), set your Supabase URL and Service Key.
# Get your SUPABASE_URL from the API section of your Supabase project settings -
# https://supabase.com/dashboard/project/<your project ID>/settings/api
SUPABASE_URL=

# Get your SUPABASE_SERVICE_KEY from the API section of your Supabase project settings -
# https://supabase.com/dashboard/project/<your project ID>/settings/api
# On this page it is called the service_role secret.
SUPABASE_SERVICE_KEY=

# OpenAI API retry configuration
# Maximum number of retries for OpenAI API calls (default: 3)
OPENAI_MAX_RETRIES=3

# Initial delay between retries in seconds (default: 1.0)
OPENAI_RETRY_DELAY=1.0

# Timeout for OpenAI API calls in seconds (default: 30)
OPENAI_TIMEOUT=30

# Batch processing configuration
# Number of text chunks to send to OpenAI embeddings API in one request (default: 20)
EMBEDDING_BATCH_SIZE=20

# Number of documents to process in memory at once during crawling (default: 10)
DOCUMENT_BATCH_SIZE=10

# Thread pool configuration
# Maximum concurrent threads for generating contextual embeddings (default: 10)
THREAD_POOL_MAX_WORKERS=10

# Crawler configuration
# Memory threshold percentage for the adaptive memory dispatcher (default: 70.0)
CRAWLER_MEMORY_THRESHOLD=70.0

# Interval in seconds for checking memory usage (default: 1.0)
CRAWLER_CHECK_INTERVAL=1.0

# Timeout for crawler operations in milliseconds (default: 30000)
CRAWLER_TIMEOUT=30000

# Maximum document length to process (default: 25000)
MAX_DOCUMENT_LENGTH=25000

# Maximum recursion depth for parsing nested sitemap indexes (default: 2)
SITEMAP_MAX_DEPTH=2

# Failure threshold for batch processing (default: 0.5 = 50%)
# If more than this percentage of batches fail, the entire operation will fail
BATCH_FAILURE_THRESHOLD=0.5